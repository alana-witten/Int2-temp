# -*- coding: utf-8 -*-
"""flowers, 22%.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gUOEaKv4PrLIDtey65wKoqEoN6Nyl1Am
"""

import matplotlib.pyplot as plt
import numpy as np
import PIL
import tensorflow as tf
import tensorflow_datasets as tfds
import pathlib

from tensorflow import keras
from tensorflow.keras import layers
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense
from tensorflow.keras.models import Sequential



#Hyperparameters
epochs=10
batch_size=32
learning_rate=0.001

height = 128
width = 128
channel = 3
input_shape = (height, width, channel)

from tensorflow_datasets.core.features.dataset_feature import Dataset
#load the dataset with tfds and split into train, validate and test
flowers, flowers_info = tfds.load('oxford_flowers102', as_supervised = True, with_info = True)
flowers_train_raw, flowers_valid_raw, flowers_test_raw = flowers['train'], flowers['validation'], flowers['test']

#Uses for manual testing, can be deleted later.
#prints out a untouched image and a augmented one
def visualize(original, augmented):
  fig = plt.figure()
  plt.subplot(1,2,1)
  plt.title('Original image')
  plt.imshow(original)

  plt.subplot(1,2,2)
  plt.title('Augmented image')
  plt.imshow(augmented)

#express the dataset in its splits
training_length = len(flowers_train_raw)
validation_length = len(flowers_valid_raw)
test_length = len(flowers_test_raw)
print(training_length)

#testing out image resizing and rescaling
def imageProcess(image, label):
  image = tf.cast(image, tf.float32)
  #resizes image
  image = tf.image.resize(image, (height, width))
  return image, label

#train and valid are now (32 * 128 * 128 * 3) tensors
#that is 32 separate 128 * 128 images in one. (3 represents the RGB values)
flowers_train = flowers_train_raw.map(imageProcess)
flowers_valid = flowers_valid_raw.map(imageProcess)
flowers_test = flowers_test_raw.map(imageProcess)

def imageRot90(image, label):
# 	image = tf.image.random_flip_left_right(image)
# 	image = tf.image.random_flip_up_down(image)
    image = tf.image.rot90(image)
    return (image, label)

def imageRot180(image, label):
    image = tf.image.rot90(image)
    image = tf.image.rot90(image)
    return (image, label)

# imageAug = tf.keras.Sequential(
#     [
#         layers.RandomFlip("horizontal"),
#         layers.RandomRotation(0.1),
#         layers.RandomZoom(0.1),
#     ]
# )

# flowers_train_aug = flowers_train_new.map(lambda x, y: (imageAug(x), y)

# flowers_train_new = flowers_train.repeat(1)
# flowers_train_aug = flowers_train_new.map(imageRot90)
# flowers_train = flowers_train.concatenate(flowers_train_aug)

# flowers_train_new = flowers_train.repeat(1)
# flowers_train_aug = flowers_train_new.map(imageRot180)
# flowers_train = flowers_train.concatenate(flowers_train_aug)

flowers_train_length = len(flowers_train)
print(flowers_train_length)

flowers_train = flowers_train.batch(batch_size)
flowers_valid = flowers_valid.batch(batch_size)
flowers_test = flowers_test.batch(batch_size)

flowers_info.features['label']

image_count = training_length + validation_length + test_length

class_names = flowers_info.features['label']
print(class_names.names)
num_classes = len(class_names.names)

# AUTOTUNE = tf.data.AUTOTUNE

# # shuffle and batched
# def configure_for_performance(ds):
#   ds = ds.cache()
#   ds = ds.shuffle(buffer_size=1000)
#   ds = ds.batch(batch_size)
#   ds = ds.prefetch(buffer_size=AUTOTUNE)
#   return ds

# flowers_train = configure_for_performance(flowers_train)
# flowers_valid = configure_for_performance(flowers_valid)

# AUTOTUNE = tf.data.AUTOTUNE

# flowers_train = flowers_train.cache().prefetch(buffer_size=AUTOTUNE)
# flowers_valid = flowers_valid.cache().prefetch(buffer_size=AUTOTUNE)

# #duplicating the training data
# flowers_train_raw_new = Dataset
# for x in range(4):
#   for img, label in flowers_train_raw:
#     rotated = tf.image.rot90(img)
 

# visualize(img, rotated)

# image_aug = tf.keras.preprocessing.image.ImageDataGenerator(
#     featurewise_center=False,
#     samplewise_center=False,
#     featurewise_std_normalization=False,
#     samplewise_std_normalization=False,
#     zca_whitening=False,
#     zca_epsilon=1e-06,
#     rotation_range=30,
#     width_shift_range=0.2,
#     height_shift_range=0.2,
#     brightness_range=[0.4,1.5]),
#     shear_range=0.0,
#     zoom_range=0.3,
#     channel_shift_range=0.0,
#     fill_mode='nearest',
#     cval=0.0,
#     horizontal_flip=True,
#     vertical_flip=True,
#     rescale=True,
#     preprocessing_function=None,
#     data_format=None,
#     validation_split=0.0,
#     interpolation_order=1,
#     dtype=None
# )

#model
model = Sequential()

#rescaling layer
model.add(layers.Rescaling(1./255, input_shape=input_shape))
#first full layer
model.add(layers.Conv2D(16, 3, padding = 'same', activation = 'relu'))
model.add(layers.MaxPooling2D())
# model.add(Dropout(0.5))
#second full layer
model.add(layers.Conv2D(32, 3, padding = 'same', activation = 'relu'))
model.add(layers.MaxPooling2D())
# model.add(Dropout(0.5))
#third full layer
model.add(layers.Conv2D(64, 3, padding = 'same', activation= 'relu'))
model.add(layers.MaxPooling2D())
# model.add(Dropout(0.5))
#flatten layer
model.add(layers.Flatten())
#first dense layer
model.add(layers.Dense(128, activation='relu'))
# model.add(Dropout(0.5))
#output layer
model.add(layers.Dense(num_classes))
# model.add(Dropout(0.5))

print(model.summary())

#compile the model
model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate),
              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics = ['accuracy'])

#train the model
history = model.fit(flowers_train, validation_data=flowers_valid, epochs=epochs, batch_size=batch_size)

#visualise training results

#accuracy
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
#loss
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(epochs)

# Plot accuracy
plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

# Plot loss function
plt.subplot(1,2,2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc = 'upper right')
plt.title('Training and Validation Loss')
plt.show()

test_images = []
test_labels = []

for image, label in flowers_test:
    test_images.append(image)
    test_labels.append(label)

test_loss = model.evaluate(test_images, test_labels)

predictions = model.predict(test_images) # vector of probabilities
pred_labels = np.argmax(predictions, axis = 1) # take the highest probability

print(classification_report(test_labels, pred_labels))

